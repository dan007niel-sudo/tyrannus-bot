import streamlit as st
import google.generativeai as genai

# --- KONFIGURATION ---
st.set_page_config(page_title="Tyrannus Technik-Bot", page_icon="üéõÔ∏è")

# Logo anzeigen (Format strikt JPG)
try:
    st.image("svt_logo.jpg", width=300)
except FileNotFoundError:
    pass # Kein Fehler anzeigen, einfach weitermachen

st.title("üéõÔ∏è Tyrannus Technik-Support")
st.caption("Dein KI-Kollege f√ºr Audio, Video & Licht")

# --- API KEY MANAGEMENT ---
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    with st.sidebar:
        api_key = st.text_input("Gib deinen Google API Key ein", type="password")
        if not api_key:
            st.warning("Bitte API Key eingeben.")

# --- SYSTEM PROMPT (DAS GEHIRN) ---
system_instruction = """
Du bist der Voice Agent des Technik-Teams der "Schule von Tyrannus" (SVT).
Deine Mission: Du sicherst den technischen Erfolg der Lehre und Gebetsn√§chte.
Haltung: Fachlich pr√§zise, entspannt, motivierend, leichter Humor ("Roadie-Slang").

STRUKTURIERTES WISSEN NACH GEWERKEN:

[TON / AUDIO]
- Hardware: Behringer XR18 Digitalmixer.
- Kanalbelegung: 
  - CH 1: Flow8/BT (Zuspieler)
  - CH 2: Cajon
  - CH 3/4: Room Mics (Atmo)
  - CH 9/10: Keys (Stereo)
  - CH 11-13: Backing Vocals (BV)
  - CH 14/15: Main Vocals (Leitung)
- Routing: BUS 1/2 = Monitore (B√ºhne), BUS 3/4 = Stream (Sende-Mix).
- Effekte (FX): FX1 Delay, FX2 Hall (Vocals), FX3 Mod Delay, FX4 Chorus.
- Logic Pro: Aufnahme l√§uft strikt ab Veranstaltungsbeginn.
- Workflow: Feedback? Zuerst Fader runter, nicht wild am EQ drehen.

[VIDEO / STREAMING]
- Software: OBS Studio.
- Hardware Status: Aktuell 1x OBSBOT Tiny 2 4K.
- Hardware Ziel (Upgrade): 2 Kameras geplant.
- WARNUNG: Bei Nutzung von zwei 4K-Webcams an einem Laptop droht "USB Bus Overload". 
  -> L√∂sung: Kameras an getrennte USB-Controller anschlie√üen.
- Zoom-Call: Originalton = AN, Ger√§uschunterdr√ºckung = NIEDRIG.

[LICHT / ATMOSPH√ÑRE]
- Fachbereich: Lichttechnik (DMX Steuerung).
- Zust√§ndigkeiten: Rigging (Sicherheit), Operating (Lichtpult), Design (Stimmung).
- Grundregel: Licht unterst√ºtzt die Atmosph√§re, es dominiert nicht.

WOCHENPLAN & ZEITEN (WICHTIG!):

[DONNERSTAG - SCHULE]
- 17:30: Treffen Technik-Team (Aufbau & Check).
- 19:00: Offizieller Start der Veranstaltung.

[FREITAG - ALLNACHT GEBET]
- 22:30: Treffen Technik-Team (Sp√§testens!).
- 23:30: Start Allnacht-Gebet.

[SONNTAG - BRIEFING]
- 22:00: Weekly Meeting (Wochenbesprechung & Planung).

REGELN F√úR DEINE ANTWORTEN:
- Fasse dich kurz. Techniker haben keine Zeit f√ºr Romane.
- Keine Listen vorlesen, f√ºhre Schritt-f√ºr-Schritt zur L√∂sung.
- Frage proaktiv nach, wenn Infos fehlen.
- Wenn jemand neu ist: Erkl√§re geduldig und nutze die Zeiten oben f√ºrs Onboarding.
"""

# --- LOGIK ---
if api_key:
    try:
        genai.configure(api_key=api_key)
        
        # Modell-Konfiguration
        model = genai.GenerativeModel(
            model_name="gemini-flash-latest",
            system_instruction=system_instruction
        )

        # Chat-Initialisierung (Session State)
        if "messages" not in st.session_state:
            st.session_state.messages = []
            # BEGR√úSSUNG (OPTION B):
            st.session_state.messages.append({
                "role": "model", 
                "parts": ["Hallo! Ich bin der Technik-Bot. Meine Aufgabe: Probleme l√∂sen und dich in Mischpult, Kamera & Licht einarbeiten. Egal ob du neu bist oder Profi ‚Äì ich sorge f√ºr den technischen Erfolg. Womit starten wir?"]
            })

        # Chat-Verlauf anzeigen
        for message in st.session_state.messages:
            with st.chat_message("user" if message["role"] == "user" else "assistant"):
                st.write(message["parts"][0])

        # Eingabe verarbeiten
        if prompt := st.chat_input("Frage stellen..."):
            st.chat_message("user").write(prompt)
            st.session_state.messages.append({"role": "user", "parts": [prompt]})

            history_for_gemini = [
                {"role": m["role"], "parts": m["parts"]} 
                for m in st.session_state.messages 
                if m["role"] != "system"
            ]
            
            chat = model.start_chat(history=history_for_gemini[:-1])
            
            with st.spinner("Checke Zeitplan & Handb√ºcher..."):
                response = chat.send_message(prompt)
            
            st.chat_message("assistant").write(response.text)
            st.session_state.messages.append({"role": "model", "parts": [response.text]})

    except Exception as e:
        st.error(f"Ein Fehler ist aufgetreten: {e}")
